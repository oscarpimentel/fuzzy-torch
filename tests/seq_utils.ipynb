{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../') # or just install the module\n",
    "sys.path.append('../../fuzzy-tools') # or just install the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 1]) tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20.]])\n",
      "torch.Size([4, 20]) tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "         0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "n = 20\n",
    "x = torch.cat([\n",
    "    torch.arange(0,n)[None],\n",
    "    torch.arange(0,n)[None],\n",
    "    torch.arange(0,n)[None],\n",
    "    torch.arange(0,n)[None],\n",
    "],dim=0)[...,None]+1\n",
    "x = x.float()\n",
    "print(x.shape, x[...,0])\n",
    "onehot = torch.zeros_like(x)[...,0]\n",
    "onehot[0,:10] = 1\n",
    "onehot[1,:] = 1\n",
    "onehot[2,:1] = 1\n",
    "print(onehot.shape, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([4, 20, 1]) tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "         15., 16., 17., 18., 19., 20.],\n",
      "        [ 1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
      "         -1., -1., -1., -1., -1., -1.]])\n",
      "torch.Size([4, 1]) tensor([10., 20.,  1., -1.])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_clean(x, onehot.bool(), -1)\n",
    "print(r.shape, r[...,0])\n",
    "r = seq_utils.seq_last_element(x, onehot.bool(), empty_seq_value=-1)\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.5\n"
     ]
    }
   ],
   "source": [
    "aa = 0\n",
    "for k in range(1, 20+1):\n",
    "    aa += k\n",
    "    \n",
    "print(aa/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([4, 1]) tensor([ 55., 210.,   1.,  -1.])\n",
      "torch.Size([4, 1]) tensor([ 5.5000, 10.5000,  1.0000, -1.0000])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_sum_pooling(x, onehot.bool(), -1)\n",
    "print(r.shape, r[...,0])\n",
    "r = seq_utils.seq_avg_pooling(x, onehot.bool(), -1)\n",
    "print(r.shape, r[...,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([4, 1]) tensor([ 5.5000, 10.5000,  1.0000,  0.0000])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([0.1818, 0.3636, 0.5455, 0.7273, 0.9091, 1.0909, 1.2727, 1.4545, 1.6364,\n",
      "        1.8182, 2.0000, 2.1818, 2.3636, 2.5454, 2.7273, 2.9091, 3.0909, 3.2727,\n",
      "        3.4545, 3.6364])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "torch.Size([4, 20, 1]) tensor([0.0952, 0.1905, 0.2857, 0.3810, 0.4762, 0.5714, 0.6667, 0.7619, 0.8571,\n",
      "        0.9524, 1.0476, 1.1429, 1.2381, 1.3333, 1.4286, 1.5238, 1.6190, 1.7143,\n",
      "        1.8095, 1.9048])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 1.0000,  2.0000,  3.0000,  4.0000,  4.9999,  5.9999,  6.9999,  7.9999,\n",
      "         8.9999,  9.9999, 10.9999, 11.9999, 12.9999, 13.9999, 14.9999, 15.9998,\n",
      "        16.9998, 17.9998, 18.9998, 19.9998])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 100000.,  200000.,  300000.,  400000.,  500000.,  600000.,  700000.,\n",
      "         800000.,  900000., 1000000., 1100000., 1200000., 1300000., 1400000.,\n",
      "        1500000., 1600000., 1700000., 1800000., 1900000., 2000000.])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_avg_pooling(x, onehot.bool())\n",
    "print(r.shape, r[...,0])\n",
    "r = seq_utils.seq_avg_norm(x, onehot.bool())\n",
    "for i in range(0,4):\n",
    "    print(onehot[i,:])\n",
    "    print(r.shape, r[i,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([4, 1]) tensor([ 55., 210.,   1.,   0.])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([0.0182, 0.0364, 0.0545, 0.0727, 0.0909, 0.1091, 0.1273, 0.1455, 0.1636,\n",
      "        0.1818, 0.2000, 0.2182, 0.2364, 0.2545, 0.2727, 0.2909, 0.3091, 0.3273,\n",
      "        0.3455, 0.3636])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "torch.Size([4, 20, 1]) tensor([0.0048, 0.0095, 0.0143, 0.0190, 0.0238, 0.0286, 0.0333, 0.0381, 0.0429,\n",
      "        0.0476, 0.0524, 0.0571, 0.0619, 0.0667, 0.0714, 0.0762, 0.0810, 0.0857,\n",
      "        0.0905, 0.0952])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 1.0000,  2.0000,  3.0000,  4.0000,  4.9999,  5.9999,  6.9999,  7.9999,\n",
      "         8.9999,  9.9999, 10.9999, 11.9999, 12.9999, 13.9999, 14.9999, 15.9998,\n",
      "        16.9998, 17.9998, 18.9998, 19.9998])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 100000.,  200000.,  300000.,  400000.,  500000.,  600000.,  700000.,\n",
      "         800000.,  900000., 1000000., 1100000., 1200000., 1300000., 1400000.,\n",
      "        1500000., 1600000., 1700000., 1800000., 1900000., 2000000.])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_sum_pooling(x, onehot.bool())\n",
    "print(r.shape, r[...,0])\n",
    "r = seq_utils.seq_sum_norm(x, onehot.bool())\n",
    "for i in range(0,4):\n",
    "    print(onehot[i,:])\n",
    "    print(r.shape, r[i,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "r torch.Size([4, 1]) tensor([1., 1., 1., 0.])\n",
      "r torch.Size([4, 1]) tensor([10., 20.,  1.,  0.])\n",
      "cpu\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([0.0000, 0.1111, 0.2222, 0.3333, 0.4444, 0.5556, 0.6667, 0.7778, 0.8889,\n",
      "        1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])\n",
      "torch.Size([4, 20, 1]) tensor([0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684, 0.4211,\n",
      "        0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895, 0.8421, 0.8947,\n",
      "        0.9474, 1.0000])\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.seq_min_pooling(x, onehot.bool())\n",
    "print('r',r.shape, r[...,0])\n",
    "r = seq_utils.seq_max_pooling(x, onehot.bool())\n",
    "print('r',r.shape, r[...,0])\n",
    "r = seq_utils.seq_min_max_norm(x, onehot.bool())\n",
    "print(r.device)\n",
    "for i in range(0,4):\n",
    "    print(onehot[i,:])\n",
    "    print(r.shape, r[i,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([5, 10]) tensor([[ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True, False, False, False, False, False, False, False, False],\n",
      "        [ True, False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "r = seq_utils.get_seq_onehot_mask(torch.tensor([5,7,2,1,0]), 10)\n",
    "print(r.shape, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([4, 20]) tensor([1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 1.,  2.,  3., 10.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.])\n",
      "***\n",
      "torch.Size([4, 20]) tensor([1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([ 1.,  3.,  8., 12.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.])\n",
      "***\n",
      "torch.Size([4, 20]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([13., 14., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.])\n",
      "***\n",
      "torch.Size([4, 20]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([4, 20, 1]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "\n",
    "onehot = torch.zeros_like(x)[...,0]\n",
    "onehot[0,0] = 1\n",
    "onehot[0,1] = 1\n",
    "onehot[0,2] = 1\n",
    "onehot[0,9] = 1\n",
    "\n",
    "onehot[1,0] = 1\n",
    "onehot[1,2] = 1\n",
    "onehot[1,7] = 1\n",
    "onehot[1,11] = 1\n",
    "\n",
    "onehot[2,12] = 1\n",
    "onehot[2,13] = 1\n",
    "onehot[2,14] = 1\n",
    "\n",
    "p = seq_utils.serial_to_parallel(x, onehot.bool())\n",
    "for i in range(0,len(onehot)):\n",
    "    print(onehot.shape, onehot[i,:])\n",
    "    print(p.shape, p[i,:,0])\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "torch.Size([2, 20, 1]) tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
      "        15., 16., 17., 18., 19., 20.])\n",
      "torch.Size([2, 20, 1]) tensor([ 6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.])\n",
      "******************************\n",
      "torch.Size([2, 20]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1]],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([2, 20, 1]) tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  8.,  9., 12., 13., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "***************\n",
      "torch.Size([2, 20]) tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0]],\n",
      "       dtype=torch.int32)\n",
      "torch.Size([2, 20, 1]) tensor([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 6., 10., 11., 14.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.,  0.,  0.,  0.,  0.]])\n",
      "***************\n",
      "******************************\n",
      "torch.Size([2, 20, 1]) tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "torch.Size([2, 20, 1]) tensor([ 6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import fuzzytorch.models.seq_utils as seq_utils\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "y = torch.clone(x).float()[:2]\n",
    "y[1] = y[1]+5\n",
    "y[0,20:,:] = 0\n",
    "y[1,10:,:] = 0\n",
    "print(y.shape, y[0,:,0])\n",
    "print(y.shape, y[1,:,0])\n",
    "print('***'*10)\n",
    "y_onehot = seq_utils.get_random_onehot(y, 2)\n",
    "y_onehot[0,:,:] = 0\n",
    "y_onehot[1,20:,:] = 0\n",
    "res = []\n",
    "for i in range(2):\n",
    "    p_y_onehot = y_onehot[...,i]\n",
    "    y_p = seq_utils.serial_to_parallel(y, p_y_onehot)\n",
    "    print(p_y_onehot.shape, p_y_onehot.int())\n",
    "    print(y_p.shape, y_p[...,0])\n",
    "    res.append(y_p)\n",
    "    print('***'*5)\n",
    "\n",
    "print('***'*10)\n",
    "s = seq_utils.parallel_to_serial(res, y_onehot)\n",
    "print(s.shape, s[0,:,0])\n",
    "print(s.shape, s[1,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
